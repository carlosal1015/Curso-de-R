---
title: "Pruebas no paramétricas"
output: html_notebook
---

Este es un [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
x <- 0:7
f <- c(35,99,104,110,62,25,10,3)
lambda <- sum(x*f)/sum(f)
esp <- dpois(x, lambda)
tba <- chisq.test(obs, p=esp, rescale.p = T)
tba # Pedimos los resultados de la variable
tba$obs
tba$exp
tba$res
```

*Ctrl+Shift+K* 

Hay pruebas que trabajan con varias muestras, en el caso del dado o en el caso del rugby, nos piden saber si es una distribución de Poisson, utilizaremos la prueba de Kolmogorov para probar la normalidad, puede probar cualquier distribución, puede probar si es $\gamma$ u otra distribución.

Distribución Uniforme se parece a una línea recta.
Distribución normal se parece a la campana de Gauss.

```{r}
# Valor semilla
set.seed(100) # Se puede usar cualquier número interno. En nuestro ejemplo es 100.

# Datos
x <- rnorm(50)
y <- runif(30)

hist(x)
hist(y)

# Prueba
ks.test(x,y) # Prueba de Kolmogorov Smirnov.
```
Si p-valor es menor que $\alpha$, entonces se rechaza la hipotesis nula.
El conjunto de datos primero no es igual conjunto de datos segundos.

# Prueba de normalidad (para una muestra)

```{r}
# Valor semilla
set.seed(100)

# Datos
x <- rnorm(50)

# Prueba
ks.test(x, pnorm, mean(x), sd(x))
```

El p-valor no es menor que $\alpha$, no se puede rechazar la hipótesis nula. Se concluye que los datos siguen una distribución normal. El $H_0$.

Siempre podremos llegar al p-valor, pero es importante su interpretación.

## ¿Los datos seguirán una distribución $\gamma$?

```{r}
# Valor semilla
set.seed(100)

# Datos
x <- rnorm(50)

# Prueba normalidad


# Prueba gamma

ks.test(x, pgamma, mean(x), sd(x))
```

¿Por qué los datos se ajustan a más de una distribución?

¿Cómo elegir la "mejor"?

Si tengo pocos datos, puedo simular muchos datos, con el Método de MonteCarlo.

Siempre cuando hay dudas, primero se realiza un análisis exploratorio, por ejemplo: histogramas, diagrama de cajas, rangos, etc. Un análisis gráficos.

Principio de Parsimonia de los modelos, el modelo más sencillo, también se conoce como navaja de Ockam.

Si mi modelo fuera $\gamma$ no se prefiere usar regresión lineal.

Otros métodos, bondada de ajusta, alkaite, modelo bayesiano. Hay varias salidas.

El test Shapiro-Wilk se usa para muestras menor a 50, muestras pequeñas, en áreas como biología. Para probar la normalidad es complicada.

```{r}
shapiro.test(x)
```
Para tamaño de muestra adecuado.

Como no se rechaza, x realmente sigue una distribución normal.

# Muestras independientes vs muestras relacionadas

Las mediciones son sobre la misma muestra o la misma poblacional (muestra relacional).

Si las muestras son de dos objetos completamente diferentes, serían muestras independientes.


Examen con 3 notas
Muestra o población: todo el salón
Son las mismas personas evaluadas en diferentes periodos del tiempo.

# Test de McNemar

En R no es fácil etiquetar una tabla

```{r}
tabla <- matrix(c(63, 21, 4, 2), byrow = TRUE, nrow = 2, ncol = 2); tabla

colnames(tabla) <- c("Diestro", "Surdo")
rownames(tabla) <- c("Hombre", "Mujer")
names(dimnames(tabla)) <- c("Género", "DZ")

tabla
```

Solo hay dos variables (genero, dz) y cada variable tiene sus categorías.

```{r}
mc <- mcnemar.test(table, correct = FALSE)
```

Se rechaza la hipótesis nula. Por lo tanto, los tiempos son diferentes.

No siempre es una data, esta vez requirió una tabla de doble entrada para realizar la prueba de Mc-Nemar.


Si es una muestra, será una sola variable, la mediana es de frecuencia central, solo es válida cuando puede establecer un tipo de orden, al menos de tipo ordinal.

```{r}
library(BSDA)
# Prueba del signo para 1 muestra
x1<-c(1.5,2.2,0.9,1.3,2.0,1.6,1.8,1.5,2.0,1.2,1.7)
BSDA::SIGN.test(x1, md = 1.8, alternative = "two.sided", conf.level =0.95)
```

Como no se rechaza la hipótesis nula, entonces se acepta que la mediana está entre los parámetro
La hipótesis es igual a 1.8. Nos interesa saber la hipótesis nula y no la hipótesis alterna.

# Caso para dos muestras relacionadas

El valor estimado  es la mediana 1.6 es de la muestra, la **mediana 1.8 es la medida de la población**.
La conclusión que hemos hecho es a nivel poblacional, toda prueba de hipótesis apunta a la población, no apunta a la muestra.

Nunca tuvimos la población, pero estamos concluyendo para la población, estamos infiriendo. El valor 1.8 es un supuesto. Un ejemplo es de un inventario del año pasado, o del ciclo pasado, sino usar una muestra piloto. Sino usar referencias bibliográficas.


```{r}
library(BSDA)
#Prueba del signo para 2 muestras relacionadas
before<-c(4.2,4.7,6.6,7.0,6.7,4.5,5.7,6.0)
after<-c(4.1,4.9,6.2,6.9,6.8,4.4,5.7,5.8)

# Remark:
# md
# before - after = 0
# before = after

SIGN.test(before,after, md = 0,
          alternative = "two.sided", conf.level = 0.95)
# p-vañue = 0.4531 no es menor que alfa 0.05, no se rechaza H_0
# entonces; antes = despues
```

Se quiere probar que la mediana es md == 0.


Puede que en el transcurso del tiempo un . Por ejemplo se evalúa lsa notas, se capacita, se espera que debería de aumentar sus notas.

```{r}
# Hipótesis:
# H_0: antes-después =0
# H_1 antes - después <> 0

# Observación:
#md = 0
## antes - después = 0
# antes = desupués

SIGN.test(antes, despues, md=0,
          alternative = "two.sided", conf.level = 0.95)
# p - value = 0.4531 no es menor que alfa 0.05, no se rechaza H_0
# entonces; antes = después

# Pero, si después de un tiempo la variable desminuye (En la diaposotova anterior mostré un tabla como esta)
# la nueva hipótesis
# H_0: antes-después < 0  o =0
# H_!: antes - después (desigualdad de ">")

#       5   -     2 > 0 dismunuido
# pero. 5 - 10 < 0
SIGN.test(antes, despues, md = 0,
          alternative = "greater", conf.level = 0.95)
# p-value: 0.2266 no es menor que alfa 0.05, no se rechaza H0
# entonces; antes <0 = después

# Para hipótesis unilateral
```

No es necesario que tengan la misma longitud

```{r}
x <- c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73,1.46)
y <- c(1.15, 0.88, 0.90, 0.74, 1.21)
wilcox.test(x, y, alternative = "l")
wilcox.test(x, y, alternative = "g")

```
Para factores se usa el comando `gl()`


res es la variable independiente (0,1) y sportsman es un factor y game otro factor.

```{r}
library(RVAideMemoire)
# prueba de Cochran 
res<-c(1,1,1,1,1,1,0,1,0,1,1,0,0,0,0,1,1,1,1,1,1,1,1,0,
       0,0,1,0,1,0,1,1,1,1,1,1)
sportsman=gl(3,1,36,labels=LETTERS[1:3])
game<-gl(12,3,labels=letters[1:12])
mat<-cbind(res,sportsman,game)
mat
cochran.qtest(res~sportsman|game)
```

```{r}
data<-iris
local({
  .Responses <- na.omit(with(iris, cbind(Petal.Length, Petal.Width, 
  Sepal.Length, Sepal.Width)))
  cat("\nMedians:\n") 
  print(apply(.Responses, 2, median)) 
  friedman.test(.Responses)
})
```

